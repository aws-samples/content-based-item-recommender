{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe11fd3-1810-4ba0-aafb-f7b563bfe5ec",
   "metadata": {},
   "source": [
    "# 01. Loading Data into Vector Database\n",
    "\n",
    "In this notebook we will prepare and load some data into the vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c210a8d-371d-4c57-99a6-fc59af45f0c4",
   "metadata": {},
   "source": [
    "**!!!IMPORTANT!!!**\n",
    "One cell in this notebook (by default commented) drops table on the database. Use with care. Avoid running all this notebook with \"Run all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a5b0d-f086-4e7f-8d3e-7693c4bfc3ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c33d31",
   "metadata": {},
   "source": [
    "**!!!MANUAL STEP!!!**\n",
    "\n",
    "You need to request certain model access in Amazon Bedrock. Follow the steps in https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html#add-model-access.\n",
    "\n",
    "Make sure to set the AWS region right before requesting model access. By default, you need these models: \n",
    "1. Titan Embeddings G1 - Text\n",
    "2. Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87eb8c7-413f-4990-93bf-0d18bc886956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f37c1-85d0-4b5d-ae95-4b7efd44e448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json, time, os, uuid, shutil\n",
    "import psycopg2\n",
    "from helper.bastion import find_instances\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5257cd74-89e4-4f00-a13a-f5ef51c6370d",
   "metadata": {},
   "source": [
    "### 2. Create the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51931966-fc23-4251-925d-94f38ef23acb",
   "metadata": {},
   "source": [
    "The following dataset is a mock dataset used for illustration on how to use this solution and for demo purpose only. \n",
    "\n",
    "Ideally you should use your own dataset and copy/upload it to the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b561b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./data/data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554de970-0d01-4f54-9e2a-23fbc5c57484",
   "metadata": {},
   "source": [
    "### 3. Configure Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09caea4d-6bad-4a40-8851-8f38a765fbb1",
   "metadata": {},
   "source": [
    "Load the output variables from the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97e410-d1bf-4b87-a794-ff17c66730bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deployment_output = json.load(open(\"./deployment-output.json\",\"r\"))\n",
    "rds_host = deployment_output[\"RecommenderStack\"][\"dbwriterendpoint\"]\n",
    "bastion_asg = deployment_output[\"RecommenderStack\"][\"bastionhostasgname\"]\n",
    "bastion_id = find_instances(bastion_asg) if bastion_asg != \"\" else None\n",
    "connect_to_db_via_bastion = False # Set to True if you are running this Notebook without VPC connection to the DB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2cf077-ff7d-48e7-b53b-bc0b7ab94f7a",
   "metadata": {},
   "source": [
    "Configure the Database class to interact with the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6a52c-e331-400a-aa76-8c3cb79322a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Database():\n",
    "    def __init__(self, writer, bastion_id=None, embedding_dimension=1536, port=5432, database_name=\"vectordb\"):\n",
    "        self.writer_endpoint = writer\n",
    "        self.username = None\n",
    "        self.password = None\n",
    "        self.port = port\n",
    "        self.database_name = database_name\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.bastion_id = bastion_id # Also indicates that DB commands are run via a bastion host with AWS SSM.\n",
    "        self.conn = None\n",
    "    \n",
    "    def fetch_credentials(self):\n",
    "        secrets_manager = boto3.client(\"secretsmanager\")\n",
    "        credentials = json.loads(secrets_manager.get_secret_value(\n",
    "            SecretId='AuroraClusterCredentials'\n",
    "        )[\"SecretString\"])\n",
    "        self.username = credentials[\"username\"]\n",
    "        self.password = credentials[\"password\"]\n",
    "    \n",
    "    def connect_for_writing(self):\n",
    "        if self.username is None or self.password is None: self.fetch_credentials()\n",
    "        \n",
    "        conn = psycopg2.connect(host=self.writer_endpoint, port=self.port, user=self.username, password=self.password, database=self.database_name)\n",
    "        conn.autocommit = True\n",
    "        self.conn = conn\n",
    "        \n",
    "        return conn\n",
    "    \n",
    "    def close_connection(self):\n",
    "        if self.conn is not None:\n",
    "            self.conn.close()\n",
    "            self.conn = None\n",
    "    \n",
    "    def create_pgvector_extension(self):\n",
    "        return self.query_database(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    \n",
    "    # This might error out if the table already exists.\n",
    "    def create_vector_table(self):\n",
    "        response = self.query_database(f\"CREATE TABLE items (id bigserial PRIMARY KEY, description text, embedding vector({str(self.embedding_dimension)}));\")\n",
    "        return response\n",
    "        \n",
    "    def insert_vector(self, query_template, text, embedding, additional_query_parameters = []):\n",
    "        text = psycopg2.extensions.adapt(text)\n",
    "        \n",
    "        all_query_parameters = [text, str(embedding)] + additional_query_parameters\n",
    "        query_statement = query_template.format(*all_query_parameters)\n",
    "        \n",
    "        return self.query_database(query_statement)\n",
    "    \n",
    "    def add_hnsw_index(self):\n",
    "        return self.query_database(\"CREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\")\n",
    "    \n",
    "    def query_database(self, query, tuples_only_and_unaligned=False):\n",
    "        if self.username is None or self.password is None: self.fetch_credentials()\n",
    "        \n",
    "        ssm = boto3.client(\"ssm\")\n",
    "        \n",
    "        #print(query)\n",
    "        \n",
    "        if self.bastion_id is None or not connect_to_db_via_bastion:\n",
    "            if self.conn is None: self.connect_for_writing()\n",
    "            \n",
    "            cur = self.conn.cursor()\n",
    "            cur.execute(query)\n",
    "\n",
    "            try:\n",
    "                result = cur.fetchall()\n",
    "            except Exception as e:\n",
    "                if str(e) != \"no results to fetch\": print(e)\n",
    "                result = cur.statusmessage\n",
    "\n",
    "            cur.close()\n",
    "            return result\n",
    "            \n",
    "        else:\n",
    "            query_id = str(uuid.uuid4())[:8]\n",
    "            query_modifier = \" -At\" if tuples_only_and_unaligned  else \"\" \n",
    "            query_command = f\"\"\"export PGPASSWORD='{self.password}' && echo \"{query}\" > ./q{query_id}.txt && psql -h {self.writer_endpoint} -p 5432 -U {self.username} -d {self.database_name} -f ./q{query_id}.txt {query_modifier} && rm ./q{query_id}.txt\"\"\"\n",
    "\n",
    "            response = ssm.send_command(\n",
    "                        InstanceIds=[self.bastion_id],\n",
    "                        DocumentName=\"AWS-RunShellScript\",\n",
    "                        Parameters={'commands': [query_command]})\n",
    "\n",
    "            command_id = response['Command']['CommandId']\n",
    "            flight_flag = True\n",
    "            while flight_flag:\n",
    "                try:\n",
    "                    output = ssm.get_command_invocation(\n",
    "                      CommandId=command_id,\n",
    "                      InstanceId=self.bastion_id\n",
    "                    )\n",
    "                    flight_flag = False\n",
    "  \n",
    "                    output_string = \"\"\n",
    "                    if output[\"StandardOutputContent\"] != '': output_string = output[\"StandardOutputContent\"]\n",
    "                    if output[\"StandardOutputUrl\"] !=  '': output_string = output[\"StandardOutputUrl\"]\n",
    "                    if output[\"StandardErrorContent\"] !=  '': output_string = output[\"StandardErrorContent\"]\n",
    "                    if output[\"StandardErrorUrl\"] !=  '': output_string = output[\"StandardErrorUrl\"]\n",
    "\n",
    "                    if output[\"StandardErrorContent\"] !=  '' or output[\"StandardErrorUrl\"] !=  '':\n",
    "                        print(output_string)\n",
    "\n",
    "                    return output_string\n",
    "                except:\n",
    "                    time.sleep(1)\n",
    "            return output_string\n",
    "\n",
    "db = Database(writer=rds_host, bastion_id=bastion_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d0869-bf37-491c-b52b-b19f0a8e3e57",
   "metadata": {},
   "source": [
    "Test the connection. If this fails with error \"relation \"items\" does not exist\", then the connection is doing fine but the table is not yet created. If this is the case, uncomment the next cell and run it.\n",
    "\n",
    "If the cell below just keeps on running for long time without giving output, likely there is an issue with the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68cbd9-e0cb-49c8-86ad-171635e0c7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(db.query_database(\"SELECT Count(*) FROM items;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778fb6a-5efb-4482-9b83-a643318fa56d",
   "metadata": {},
   "source": [
    "Set up the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040fe98-8efb-4cd2-91ee-ab1190c0263a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The infrastructure deployment should already installed the pgVector extension and created the table for you. \n",
    "# Only uncomment run below code if the pgVector extension was not installed as it was supposed to be or if the table was not created respectively.\n",
    "\n",
    "#db.create_pgvector_extension();\n",
    "#db.create_vector_table();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de7614-f4ea-4302-88d1-f562d9fabd5b",
   "metadata": {},
   "source": [
    "Define query statement template to insert data. This is the part where you can customize.\n",
    "\n",
    "Since this solution is customizable, it allows you to customer the vector insert query. It will then be uploaded to S3 (in notebook 03) and be used by the Lambda function in the actual inference.\n",
    "\n",
    "Note that the AWS Lambda that backs the API is set to run `.format(*parameters)` from this template, while `parameters` will be a merged array of `[text, embedding]` and any additional parameters you supply during inference time. For example, if you want to add more columns to be used with the WHERE clause during search/query time, you can do so by adding the placeholder values for those column data as {2}, {3}, and so on in this template. You must remember to supply these parameters via `additional_query_parameters` when invoking the data loading API. By default the `additional_query_parameters` is and empty list `[]`.\n",
    "\n",
    "As a restriction, {0} has to be the text description of the item and {1} has to be the embedding to inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ea19f-7fc0-4fbb-887c-8cd831764ffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_template = \"INSERT INTO items (description,embedding) VALUES ( {0} ,'{1}');\"\n",
    "\n",
    "# Store it on disk\n",
    "path = \"vector_insert_query.txt\" # Do not change the naming of the file\n",
    "f = open(path, \"w\")\n",
    "f.write(query_template)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb26704-a1c0-4274-9440-db42dbfac792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign the value for additional query parameters (if any) now for testing\n",
    "additional_query_parameters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a297ce-afa0-4ea2-8bc4-b77711ce3c78",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81be88b-5363-4606-a96e-b7be0745cb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The file path of your dataset in the local disk. Change as necessary.\n",
    "data_file_path = \"data/data.txt\"\n",
    "# The delimiter of data points in your dataset file. Change as necessary.\n",
    "data_delimiter=\"###\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912cf59-438e-49cf-8d80-7df9c306aacf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_string = open(data_file_path, \"r\").read()\n",
    "data = data_string.split(data_delimiter) if data_delimiter in data_string else [data_string]\n",
    "for text in data:\n",
    "\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"inputText\": text,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock.invoke_model(body=body, modelId=\"amazon.titan-embed-text-v1\")\n",
    "    embedding = json.loads(response.get(\"body\").read())[\"embedding\"]\n",
    "    res = db.insert_vector(query_template, text, embedding, additional_query_parameters=additional_query_parameters)\n",
    "    \n",
    "#db.add_hnsw_index(); # This may on work on Aurora PostgreSQL Engine with version > 15.4. Currently the infrastructure is deployed with version 15.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8bd0ed-ca19-4a89-a0d4-08279d6cf1ba",
   "metadata": {},
   "source": [
    "Make sure data insertion worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467966ae-1174-4e01-9206-7d8b076390c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(db.query_database(\"SELECT Count(*) FROM items;\"))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
